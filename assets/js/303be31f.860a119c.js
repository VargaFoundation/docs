"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2284],{8453:(n,e,r)=>{r.d(e,{R:()=>s,x:()=>a});var t=r(6540);const i={},o=t.createContext(i);function s(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:s(n.components),t.createElement(o.Provider,{value:e},n.children)}},9425:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>s,metadata:()=>t,toc:()=>p});const t=JSON.parse('{"id":"tarn/examples","title":"Examples","description":"Model Repository Structure","source":"@site/docs/tarn/examples.md","sourceDirName":"tarn","slug":"/tarn/examples","permalink":"/tarn/examples","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/tarn/examples.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"id":"examples","title":"Examples","sidebar_position":10},"sidebar":"tutorialSidebar","previous":{"title":"Compatibility","permalink":"/tarn/compatibility"},"next":{"title":"Nexberos","permalink":"/category/nexberos"}}');var i=r(4848),o=r(8453);const s={id:"examples",title:"Examples",sidebar_position:10},a=void 0,l={},p=[{value:"Model Repository Structure",id:"model-repository-structure",level:2},{value:"1. Stable Diffusion (Image Generation)",id:"1-stable-diffusion-image-generation",level:2},{value:"2. ONNX Model (ResNet-50)",id:"2-onnx-model-resnet-50",level:2},{value:"3. PyTorch Model (LibTorch)",id:"3-pytorch-model-libtorch",level:2}];function c(n){const e={code:"code",h2:"h2",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h2,{id:"model-repository-structure",children:"Model Repository Structure"}),"\n",(0,i.jsx)(e.p,{children:"The Triton Inference Server organizes models in a model repository:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"<model-repository-path>/\r\n   <model-name>/\r\n       [config.pbtxt]\r\n       [<output-labels-file> ...]\r\n       [configs/]\r\n           [<custom-config-file> ...]\r\n       <version>/\r\n           <model-definition-file>\r\n       <version>/\r\n           <model-definition-file>\n"})}),"\n",(0,i.jsx)(e.p,{children:"Example:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"model_repository\r\n|\r\n+-- resnet50\r\n    |\r\n    +-- config.pbtxt\r\n    +-- 1\r\n        |\r\n        +-- model.pt\r\n+-- densenet_onnx\r\n    |\r\n    +-- config.pbtxt\r\n    +-- 1\r\n        |\r\n        +-- model.onnx   \n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"config.pbtxt"})," (optional, auto-generated if missing):"]}),"\n",(0,i.jsx)(e.p,{children:"Example for ONNX:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'name: "text_detection"\r\nbackend: "onnxruntime"\r\nmax_batch_size: 256\r\ninput [\r\n   {\r\n       name: "input_images:0"\r\n       data_type: TYPE_FP32\r\n       dims: [ -1, -1, -1, 3 ]\r\n   }\r\n]\r\noutput [\r\n   {\r\n       name: "feature_fusion/Conv_7/Sigmoid:0"\r\n       data_type: TYPE_FP32\r\n       dims: [ -1, -1, -1, 1 ]\r\n   }\r\n]\n'})}),"\n",(0,i.jsx)(e.h2,{id:"1-stable-diffusion-image-generation",children:"1. Stable Diffusion (Image Generation)"}),"\n",(0,i.jsx)(e.p,{children:"Deploy:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"yarn jar target/tarn-orchestrator-0.0.1-SNAPSHOT.jar varga.tarn.yarn.Client \\\r\n  --model-repository hdfs:///models \\\r\n  --image nvcr.io/nvidia/tritonserver:24.09-py3 \\\r\n  --token secret-token\n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Client (Python)"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\nfrom PIL import Image\r\nfrom tritonclient.http import InferenceServerClient, InferInput\r\n\r\n# Connect to HAProxy or Triton instance\r\nclient = InferenceServerClient(url="localhost:8000")\r\n\r\nprompt = "A futuristic city in the style of cyberpunk"\r\ninput_data = np.array([prompt], dtype=object)\r\n\r\ninputs = [InferInput("PROMPT", [1], "BYTES")]\r\ninputs[0].set_data_from_numpy(input_data)\r\n\r\nresponse = client.infer("stable_diffusion", inputs)\r\n\r\nimage_data = response.as_numpy("IMAGES")[0]\r\nimage = Image.fromarray(image_data.astype(np.uint8))\r\nimage.save("generated_image.png")\n'})}),"\n",(0,i.jsx)(e.h2,{id:"2-onnx-model-resnet-50",children:"2. ONNX Model (ResNet-50)"}),"\n",(0,i.jsx)(e.p,{children:"Deploy:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"yarn jar target/tarn-orchestrator-0.0.1-SNAPSHOT.jar varga.tarn.yarn.Client \\\r\n  --model-repository hdfs:///models \\\r\n  --image nvcr.io/nvidia/tritonserver:24.09-py3\n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Client (Python)"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\nimport tritonclient.http as httpclient\r\n\r\nclient = httpclient.InferenceServerClient(url="localhost:8000")\r\n\r\ninput_shape = (1, 3, 224, 224)\r\ndata = np.random.randn(*input_shape).astype(np.float32)\r\n\r\ninputs = [httpclient.InferInput("input_0", input_shape, "FP32")]\r\ninputs[0].set_data_from_numpy(data)\r\n\r\nresults = client.infer("onnx_resnet50", inputs)\r\noutput_data = results.as_numpy("output_0")\r\nprint(f"Inference result shape: {output_data.shape}")\n'})}),"\n",(0,i.jsx)(e.h2,{id:"3-pytorch-model-libtorch",children:"3. PyTorch Model (LibTorch)"}),"\n",(0,i.jsx)(e.p,{children:"Deploy same as above."}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Client (Python)"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\nimport tritonclient.http as httpclient\r\n\r\nclient = httpclient.InferenceServerClient(url="localhost:8000")\r\n\r\ndata = np.random.randn(1, 3, 224, 224).astype(np.float32)\r\n\r\ninputs = [httpclient.InferInput("INPUT__0", [1, 3, 224, 224], "FP32")]\r\ninputs[0].set_data_from_numpy(data)\r\n\r\nresponse = client.infer("pytorch_densenet", inputs)\r\nprobabilities = response.as_numpy("OUTPUT__0")\r\npredicted_class = np.argmax(probabilities)\r\nprint(f"Predicted class ID: {predicted_class}")\n'})})]})}function d(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(c,{...n})}):c(n)}}}]);