"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4898],{2057:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"tarn/index","title":"TARN \u2014 Triton on YARN","description":"TARN is a scalable inference solution for running NVIDIA Triton Inference Server on a Hadoop/YARN cluster using Docker containers.","source":"@site/docs/tarn/index.md","sourceDirName":"tarn","slug":"/tarn/","permalink":"/tarn/","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/tarn/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"index","title":"TARN \u2014 Triton on YARN","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Tarn","permalink":"/category/tarn"},"next":{"title":"Prerequisites & Resources","permalink":"/tarn/prerequisites-resources"}}');var i=r(4848),o=r(8453);const a={id:"index",title:"TARN \u2014 Triton on YARN",sidebar_position:1},s=void 0,c={},l=[{value:"Architecture",id:"architecture",level:2},{value:"What you&#39;ll find here",id:"what-youll-find-here",level:2}];function d(e){const n={code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"TARN is a scalable inference solution for running NVIDIA Triton Inference Server on a Hadoop/YARN cluster using Docker containers."}),"\n",(0,i.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:'graph TB\r\n    %% Client\r\n    Client[Client]\r\n\r\n    %% Perimeter Security & LB\r\n    subgraph Perimeter ["Secure Gateway"]\r\n        HA[HAProxy Instance]\r\n        Knox[Apache Knox Gateway]\r\n        Updater[HAProxy Updater Script]\r\n    end\r\n\r\n    %% ZooKeeper\r\n    ZK((ZooKeeper))\r\n\r\n    %% YARN Cluster\r\n    subgraph YARN ["YARN Cluster"]\r\n        RM[Resource Manager]\r\n\r\n        subgraph NM1 ["Node Manager 1"]\r\n            AM[Application Master]\r\n        end\r\n\r\n        subgraph NM2 ["Node Manager 2"]\r\n            TC1[Triton Container 1\r\nGPU Allocated]\r\n            NFS1[HDFS NFS Gateway 1]\r\n        end\r\n\r\n        subgraph NM3 ["Node Manager 3"]\r\n            TC2[Triton Container 2\r\nGPU Allocated]\r\n            NFS2[HDFS NFS Gateway 1]\r\n        end\r\n\r\n        TC1 --\x3e|3. Load model| NFS1\r\n        TC2 --\x3e|3. Load model| NFS2\r\n    end\r\n\r\n    %% HDFS\r\n    subgraph HDFS ["HDFS"]\r\n        NN[NameNode]\r\n        DN[DataNode]\r\n    end\r\n\r\n    %% Connexions principales (flux vertical)\r\n    Client --\x3e|Inference Request| HA\r\n    Client --\x3e|Secure Inference Request| Knox\r\n    HA --\x3e|Load Balances| TC1\r\n    HA --\x3e|Load Balances| TC2\r\n    Knox --\x3e|Dynamic LB via ZK| TC1\r\n    Knox --\x3e|Dynamic LB via ZK| TC2\r\n\r\n    %% Interactions YARN\r\n    AM -.->|1. Request Resources| RM\r\n    RM -.->|2. Allocate Containers| NM2\r\n    RM -.->|2. Allocate Containers| NM3\r\n\r\n    %% ZooKeeper Registration\r\n    AM -.->|Register Instances| ZK\r\n    Knox -.->|Discover Instances| ZK\r\n\r\n    %% D\xe9couverte et mise \xe0 jour HAProxy\r\n    Updater -.->|4. Discover AM| RM\r\n    Updater --\x3e|5. Query Instances| AM\r\n    Updater --\x3e|6. Update backend servers\r\nlist via Runtime API| HA\r\n\r\n    %% Acc\xe8s HDFS via NFS Gateway\r\n    NFS1 -.-> NN\r\n    NFS2 -.-> NN\r\n    NFS1 --\x3e DN\r\n    NFS2 --\x3e DN\r\n\r\n    %% Style pour forcer l\'empilement vertical\r\n    classDef cluster fill:#2d2d2d,stroke:#444,color:#fff;\r\n    class Perimeter,YARN,HDFS cluster;\n'})}),"\n",(0,i.jsx)(n.h2,{id:"what-youll-find-here",children:"What you'll find here"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Prerequisites and cluster sizing"}),"\n",(0,i.jsx)(n.li,{children:"Building and deploying the orchestrator"}),"\n",(0,i.jsx)(n.li,{children:"Model repository configuration (HDFS/NFS)"}),"\n",(0,i.jsx)(n.li,{children:"Load balancing and service discovery"}),"\n",(0,i.jsx)(n.li,{children:"Security with Apache Ranger"}),"\n",(0,i.jsx)(n.li,{children:"Operations, monitoring, and scaling"}),"\n",(0,i.jsx)(n.li,{children:"Examples using Open Inference Protocol"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Goal: Run production Triton Inference Server on YARN with GPU support, auto-scaling, and ecosystem integration."})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>s});var t=r(6540);const i={},o=t.createContext(i);function a(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);